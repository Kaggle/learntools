{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -t /kaggle/working/ git+https://github.com/Kaggle/learntools.git@embeddings-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -t /kaggle/working/ gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (Gensim / vector math)\n",
    "\n",
    "In this exercise, you'll get to do some of your exploration of our trained movie embeddings, using some of the Gensim tools I showed in [the tutorial](https://www.kaggle.com/colinmorris/3-exploring-embeddings-with-gensim). To get started, run the setup cell below to import the libraries we'll be using, load our raw embedding data, and wrap it in a `WordEmbeddingsKeyedVectors` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "\n",
    "from learntools.core import binder; binder.bind(globals())\n",
    "from learntools.embeddings.ex3_gensim import *\n",
    "\n",
    "RUNNING_ON_KERNELS = 'KAGGLE_WORKING_DIR' in os.environ\n",
    "input_dir = '../input/0-movielens-preprocessing' if RUNNING_ON_KERNELS else '../input/movielens_preprocessed'\n",
    "model_dir = '../input/x3-movielens-spiffy-model' if RUNNING_ON_KERNELS else '.'\n",
    "model_path = os.path.join(model_dir, 'movie_svd_model_32.h5')\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "emb_layer = model.get_layer('movie_embedding')\n",
    "(w,) = emb_layer.get_weights()\n",
    "movie_embedding_size = w.shape[1]\n",
    "\n",
    "movies_path = os.path.join(input_dir, 'movie.csv')\n",
    "all_movies_df = pd.read_csv(movies_path, index_col=0)\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "movies = all_movies_df[all_movies_df.n_ratings >= threshold].reset_index(drop=True)\n",
    "\n",
    "kv = WordEmbeddingsKeyedVectors(movie_embedding_size)\n",
    "kv.add(\n",
    "    movies['key'].values,\n",
    "    w[movies.movieId]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Warm-up\n",
    "\n",
    "As a warm-up, try using the `kv.most_similar` method on a few of your favourite movies. What do you think of the results? Are there any that stick out as being a bad match? Any movies that you think *should* be on the list but which aren't? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colinmorris/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Strangers on a Train', 0.9427046775817871),\n",
       " ('Rear Window', 0.9409477710723877),\n",
       " ('North by Northwest', 0.9366045594215393),\n",
       " ('Sunset Blvd. (a.k.a. Sunset Boulevard)', 0.9357169270515442),\n",
       " ('The Third Man', 0.9308935403823853),\n",
       " ('Maltese Falcon, The (a.k.a. Dangerous Female)', 0.9279078245162964),\n",
       " ('The Treasure of the Sierra Madre', 0.9239088296890259),\n",
       " ('The Maltese Falcon', 0.9194389581680298),\n",
       " ('Paths of Glory', 0.9179232120513916),\n",
       " ('Notorious (1946)', 0.9070533514022827)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: one of my favourite films by Alfred Hitchcock. Try with some of your favourite movies.\n",
    "kv.most_similar('Vertigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>914</td>\n",
       "      <td>Spellbound</td>\n",
       "      <td>Mystery|Romance|Thriller</td>\n",
       "      <td>Spellbound (1945)</td>\n",
       "      <td>1945</td>\n",
       "      <td>2268</td>\n",
       "      <td>3.920195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>6232</td>\n",
       "      <td>Spellbound</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Spellbound (2002)</td>\n",
       "      <td>2002</td>\n",
       "      <td>2888</td>\n",
       "      <td>3.987314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId       title                    genres                key  year  \\\n",
       "789       914  Spellbound  Mystery|Romance|Thriller  Spellbound (1945)  1945   \n",
       "4851     6232  Spellbound               Documentary  Spellbound (2002)  2002   \n",
       "\n",
       "      n_ratings  mean_rating  \n",
       "789        2268     3.920195  \n",
       "4851       2888     3.987314  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if you get a KeyError when looking up a movie, you may want to run something like this\n",
    "# to look up the 'key' column for your movie. For example, there's more than one movie with the \n",
    "# title 'Spellbound', so I need to either call:\n",
    "#     kv.most_similar('Spellbound (1945)')\n",
    "# If I want the Hitchcock thriller, or:\n",
    "#     kv.most_similar('Spellbound (2002)')\n",
    "# If I want the documentary on spelling bees.\n",
    "movies[movies.title.str.contains('Spellbound')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find any particularly interesting or funny examples, feel free to share them on [the forums](TODO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. *Bambi* + *The Mummy* = ???\n",
    "\n",
    "So far we've seen the `most_similar()` method called in the following ways:\n",
    "- with a single (positive) example `m1`, giving us the movies most similar to `m1`\n",
    "- with one positive example, `m1`, and one negative example, `m2`. The results seem to roughly correspond to the question \"which movies exemplify the properties that `m1` has and `m2` doesn't?\"\n",
    "- with two positive examples, `m1` and `m2`, and one negative example, `m3`, which answers the analogy \"`m3` is to `m2` as `m1` is to ____\".\n",
    "\n",
    "What do you think will happen (mathematically, and semantically) if we call it with two positive examples, and no negative examples? \n",
    "\n",
    "In the code cell below, try calling `most_similar()` with *Legally Blonde* and *Mission: Impossible* as two positive examples. If you're familiar with the movies, see if you can predict what kinds of movies will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 2, \"questionId\": \"2_VectorAddition\", \"interactionType\": 1, \"failureMessage\": \"Expected legally_impossible to have type `<class 'list'>` but had type `<class 'NoneType'>`\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> Expected legally_impossible to have type `<class 'list'>` but had type `<class 'NoneType'>`"
      ],
      "text/plain": [
       "Incorrect: Expected legally_impossible to have type `<class 'list'>` but had type `<class 'NoneType'>`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: call most_similar with the movies \"Legally Blonde\" and \"Mission: Impossible\" as positive examples,\n",
    "# and assign the results to the variable legally_impossible\n",
    "legally_impossible = None\n",
    "print(legally_impossible)\n",
    "part2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try experimenting with adding other pairs of movies. Do you see a pattern emerging?\n",
    "\n",
    "What do you think happens if we pass in the same movie twice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to continue experimenting here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the line below to see an explanation of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 4, \"questionId\": \"2_VectorAddition\", \"interactionType\": 3, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "legally_impossible = kv.most_similar(positive=['Legally Blonde', 'Mission: Impossible'])\n",
       "```\n",
       "\n",
       "Passing in two positive examples, `m1` and `m2`, finds the vectors that are most similar to `m1 + m2`. Semantically, this corresponds to movies that are about halfway between `m1` and `m2` in terms of meaning. \n",
       "\n",
       "In light of this interpretation, some of our `legally_impossible` results make a lot of sense. *Miss Congeniality*, *Mr. & Mrs. Smith*, and *Charlie's Angels* are all examples of movies that combine the \"chick flick comedy\" properties of *Legally Blonde* with the action/spy movie properties of *Mission: Impossible*.\n",
       "\n",
       "What happens if we run something like `kv.most_similar(positive=['Legally Blonde', 'Legally Blonde'])`? We get the exact same results as `kv.most_similar('Legally Blonde')`. The reason comes down to our use of cosine distance. If we add a movie vector `m1` to itself, we get a vector that's twice as long, but its *angle* remains the same. So for any pair of movies `m1`, `m2`, `distance.cosine(m1, m2) == distance.cosine(m1+m1, m2)`.\n"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "legally_impossible = kv.most_similar(positive=['Legally Blonde', 'Mission: Impossible'])\n",
       "```\n",
       "\n",
       "Passing in two positive examples, `m1` and `m2`, finds the vectors that are most similar to `m1 + m2`. Semantically, this corresponds to movies that are about halfway between `m1` and `m2` in terms of meaning. \n",
       "\n",
       "In light of this interpretation, some of our `legally_impossible` results make a lot of sense. *Miss Congeniality*, *Mr. & Mrs. Smith*, and *Charlie's Angels* are all examples of movies that combine the \"chick flick comedy\" properties of *Legally Blonde* with the action/spy movie properties of *Mission: Impossible*.\n",
       "\n",
       "What happens if we run something like `kv.most_similar(positive=['Legally Blonde', 'Legally Blonde'])`? We get the exact same results as `kv.most_similar('Legally Blonde')`. The reason comes down to our use of cosine distance. If we add a movie vector `m1` to itself, we get a vector that's twice as long, but its *angle* remains the same. So for any pair of movies `m1`, `m2`, `distance.cosine(m1, m2) == distance.cosine(m1+m1, m2)`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#part2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**: Pick a movie you like (let's call it `m`), and see if you can find two other movies, `m1` and `m2` such that `m1 + m2 â‰ˆ m`. Of course you're pretty likely to succeed if you choose two movies which are each similar to `m`, but can you come up with a pair of very *different* movies that have `m` right between them? Again, if you're successful here, feel free to share on [the forums](TODO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cosine distance vs. Euclidean distance\n",
    "\n",
    "If you're familiar with linear algebra, you may know that the cosine distance and euclidean distance of two vectors are equivalent (up to a scaling factor) if those vectors have the same length. In particular, when our vectors both have length 1, their euclidean distance is just twice their cosine distance.\n",
    "\n",
    "Given that we cared about using cosine distance rather than Euclidean distance, we must have some reason to believe that our embedding vectors vary in length. But how much? And is there any pattern to which movies' vectors are long or short?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Distribution of lengths\n",
    "\n",
    "Just as there are lots of definitions of distance, there are lots of definitions of length. But we'll be using the familiar notion, technically called the 'Euclidean norm' or 'L2 norm'. What's the length of the vector `(3, 4)`? Well, if we start at `(0, 0)`, walk 3 steps to the right, and then 4 steps up, we'll get a right triangle where the hypotenuse connects `(3, 4)` to `(0, 0)`. By the Pythagorean theorem, the length of that hypotenuse is $\\sqrt{3^2 + 4^2} = \\sqrt{25} = 5$. We can extend the calculation to any number of dimensions - for example, the L2 norm of the vector `(1, 1, 3, 5)` is $\\sqrt{1^2 + 1^2 + 3^2 + 5^2} = 6$.\n",
    "\n",
    "Fortunately, we don't need to implement the calculations ourselves. Given a vector, the function [`numpy.linalg.norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html) returns its L2 norm. Run the cell below to calculate the L2 norm of our model's first movie embedding vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0208979"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code in the cell below to create a variable `norms`, containing the L2 norms of all the model's movie embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 2, \"questionId\": \"3.1_CalculateNorms\", \"interactionType\": 1, \"failureMessage\": \"Expected norms to have type `<class 'numpy.ndarray'>` but had type `<class 'NoneType'>`\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> Expected norms to have type `<class 'numpy.ndarray'>` but had type `<class 'NoneType'>`"
      ],
      "text/plain": [
       "Incorrect: Expected norms to have type `<class 'numpy.ndarray'>` but had type `<class 'NoneType'>`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norms = None\n",
    "part3.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 4, \"questionId\": \"3.1_CalculateNorms\", \"interactionType\": 2, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> Check out the axis keyword of np.linalg.norm in numpy's documentation: [https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html)"
      ],
      "text/plain": [
       "Hint: Check out the axis keyword of np.linalg.norm in numpy's documentation: [https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#part3.a.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 4, \"questionId\": \"3.1_CalculateNorms\", \"interactionType\": 3, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "norms = np.linalg.norm(w, axis=1)\n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "norms = np.linalg.norm(w, axis=1)\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#part3.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've successfully calculated `norms`, run the following cell to generate a visualization of the distribution of lengths of our movie embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD8CAYAAAC/1zkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFv5JREFUeJzt3X/wXXV95/HnS36orEpAUmSSYGLN2KKr25giHaddV1YI2hJ21zo4bokua3YrtrrtjILbMV0tOzrtSsVWLZWswXUFilZShdKItG5nSiAo8lPLt/iDpCiR8EOLhQm+94/7+cbLN99vcvnm3Hu/1zwfM3e+53zO59zzPmfgvHJ+3HNSVUiS1IWnjLsASdJPDkNFktQZQ0WS1BlDRZLUGUNFktQZQ0WS1BlDRZLUGUNFktQZQ0WS1JlDx13AqB1zzDG1fPnycZchSRPlpptu+l5VLd5fv4MuVJYvX862bdvGXYYkTZQk3xqkn6e/JEmdMVQkSZ0xVCRJnRlaqCTZmOS+JLfNMu23k1SSY9p4klyYZCrJLUlW9fVdl+Su9lnX1/7SJLe2eS5MkmGtiyRpMMM8Uvk4sGZmY5JlwCnAt/uaTwNWts964COt79HABuBlwInAhiRHtXk+Ary5b769liVJGq2hhUpVfQnYNcukC4B3AP1vB1sLXFI91wOLkhwHnApsqapdVfUAsAVY06Y9q6qur95bxi4BzhjWukiSBjPSaypJ1gI7quqrMyYtAe7pG9/e2vbVvn2W9rmWuz7JtiTbdu7ceQBrIEnal5GFSpIjgHcB7x7VMqdV1UVVtbqqVi9evN/f7kiS5mmURyo/DawAvprkm8BS4MtJngPsAJb19V3a2vbVvnSWdknSGI3sF/VVdSvwU9PjLVhWV9X3kmwG3prkUnoX5R+qqnuTXAP8z76L86cA51XVriQPJzkJ2AqcBXxo2Ouw/NzPD3sRs/rm+14zluVK0pM1zFuKPwX8HfCCJNuTnL2P7lcBdwNTwJ8CbwGoql3Ae4Eb2+c9rY3W52Ntnn8Arh7GekiSBje0I5Wqev1+pi/vGy7gnDn6bQQ2ztK+DXjRgVUpSeqSv6iXJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdWZooZJkY5L7ktzW1/b7Sb6W5JYkf55kUd+085JMJfl6klP72te0tqkk5/a1r0iytbVfluTwYa2LJGkwwzxS+TiwZkbbFuBFVfVi4O+B8wCSnACcCbywzfPhJIckOQT4Y+A04ATg9a0vwPuBC6rq+cADwNlDXBdJ0gCGFipV9SVg14y2v6qq3W30emBpG14LXFpVj1bVN4Ap4MT2maqqu6vqMeBSYG2SAK8ErmjzbwLOGNa6SJIGM85rKv8JuLoNLwHu6Zu2vbXN1f5s4MG+gJpulySN0VhCJcl/B3YDnxzR8tYn2ZZk286dO0exSEk6KI08VJK8Efhl4A1VVa15B7Csr9vS1jZX+/3AoiSHzmifVVVdVFWrq2r14sWLO1kPSdLeRhoqSdYA7wBOr6pH+iZtBs5M8tQkK4CVwA3AjcDKdqfX4fQu5m9uYXQd8No2/zrgylGthyRpdsO8pfhTwN8BL0iyPcnZwB8BzwS2JLk5yUcBqup24HLgDuAvgXOq6vF2zeStwDXAncDlrS/AO4HfSjJF7xrLxcNaF0nSYA7df5f5qarXz9I8546/qs4Hzp+l/Srgqlna76Z3d5gkaYHwF/WSpM4YKpKkzhgqkqTOGCqSpM4YKpKkzhgqkqTOGCqSpM4YKpKkzhgqkqTOGCqSpM4YKpKkzhgqkqTOGCqSpM4YKpKkzhgqkqTOGCqSpM4YKpKkzhgqkqTOGCqSpM4YKpKkzhgqkqTODC1UkmxMcl+S2/rajk6yJcld7e9RrT1JLkwyleSWJKv65lnX+t+VZF1f+0uT3NrmuTBJhrUukqTBDPNI5ePAmhlt5wLXVtVK4No2DnAasLJ91gMfgV4IARuAlwEnAhumg6j1eXPffDOXJUkasaGFSlV9Cdg1o3ktsKkNbwLO6Gu/pHquBxYlOQ44FdhSVbuq6gFgC7CmTXtWVV1fVQVc0vddkqQxGfU1lWOr6t42/B3g2Da8BLinr9/21rav9u2ztEuSxmhsF+rbEUaNYllJ1ifZlmTbzp07R7FISToojTpUvttOXdH+3tfadwDL+votbW37al86S/usquqiqlpdVasXL158wCshSZrdqENlMzB9B9c64Mq+9rPaXWAnAQ+102TXAKckOapdoD8FuKZNezjJSe2ur7P6vkuSNCaHDuuLk3wKeAVwTJLt9O7ieh9weZKzgW8Br2vdrwJeDUwBjwBvAqiqXUneC9zY+r2nqqYv/r+F3h1mTweubh9J0hgNLVSq6vVzTDp5lr4FnDPH92wENs7Svg140YHUKEnqlr+olyR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdWagUEnyL4ddiCRp8g16pPLhJDckeUuSI4dakSRpYg0UKlX1i8Ab6L2F8aYk/zfJq4ZamSRp4gx8TaWq7gJ+B3gn8K+BC5N8Lcm/H1ZxkqTJMug1lRcnuQC4E3gl8CtV9bNt+IIh1idJmiCDvvnxQ8DHgHdV1Q+nG6vqH5P8zlAqkyRNnEFD5TXAD6vqcYAkTwGeVlWPVNUnhladJGmiDHpN5QvA0/vGj2htkiTtMWioPK2qfjA90oaPGE5JkqRJNWio/FOSVdMjSV4K/HAf/fcpyX9LcnuS25J8KsnTkqxIsjXJVJLLkhze+j61jU+16cv7vue81v71JKfOtx5JUjcGDZW3A3+W5P8l+VvgMuCt81lgkiXAbwKrq+pFwCHAmcD7gQuq6vnAA8DZbZazgQda+wWtH0lOaPO9EFhD7weah8ynJklSNwb98eONwM8Avw78V+Bnq+qmA1juocDTkxxK7zTavfRuT76iTd8EnNGG17Zx2vSTk6S1X1pVj1bVN4Ap4MQDqEmSdIAGvfsL4OeB5W2eVUmoqkue7AKrakeSPwC+Te8U2l8BNwEPVtXu1m07sKQNLwHuafPuTvIQ8OzWfn3fV/fPI0kag4FCJckngJ8GbgYeb80FPOlQSXIUvaOMFcCDwJ/RO301NEnWA+sBjj/++GEuSpIOaoMeqawGTqiq6mCZ/xb4RlXtBEjyGeDlwKIkh7ajlaXAjtZ/B71njm1vp8uOBO7va5/WP88TVNVFwEUAq1ev7mIdJEmzGPRC/W3Aczpa5reBk5Ic0a6NnAzcAVwHvLb1WQdc2YY3t3Ha9C+2cNsMnNnuDlsBrARu6KhGSdI8DHqkcgxwR5IbgEenG6vq9Ce7wKramuQK4MvAbuAr9I4iPg9cmuT3WtvFbZaLgU8kmQJ20bvji6q6Pcnl9AJpN3DO9C/+JUnjMWio/G6XC62qDcCGGc13M8vdW1X1z8CvzvE95wPnd1mbJGn+BgqVqvqbJM8FVlbVF5IcQe/3JZIk7THoo+/fTO83In/SmpYAnx1WUZKkyTTohfpz6N2h9TDseWHXTw2rKEnSZBo0VB6tqsemR9qtvd6aK0l6gkFD5W+SvIveo1VeRe8Hi38xvLIkSZNo0FA5F9gJ3Ar8F+Aqeu+rlyRpj0Hv/voR8KftI0nSrAZ99tc3mOUaSlU9r/OKJEkT68k8+2va0+j9GPHo7suRJE2yQd+ncn/fZ0dV/SHwmiHXJkmaMIOe/lrVN/oUekcuT+ZdLJKkg8CgwfC/+oZ3A98EXtd5NZKkiTbo3V//ZtiFSJIm36Cnv35rX9Or6gPdlCNJmmRP5u6vn6f3YiyAX6H3Qqy7hlGUJGkyDRoqS4FVVfV9gCS/C3y+qv7jsAqTJE2eQR/TcizwWN/4Y61NkqQ9Bj1SuQS4Icmft/EzgE3DKUmSNKkGvfvr/CRXA7/Ymt5UVV8ZXlmSpEk06OkvgCOAh6vqg8D2JCuGVJMkaUIN+jrhDcA7gfNa02HA/xlWUZKkyTTokcq/A04H/gmgqv4ReOZ8F5pkUZIrknwtyZ1JfiHJ0Um2JLmr/T2q9U2SC5NMJbml/5ExSda1/nclWTffeiRJ3Rg0VB6rqqI9/j7JvzjA5X4Q+Muq+hngJcCd9F4Edm1VrQSubeMApwEr22c98JFWw9HABuBlwInAhukgkiSNx6ChcnmSPwEWJXkz8AXm+cKuJEcCvwRcDFBVj1XVg8BafnxH2SZ6d5jR2i+pnutbDccBpwJbqmpXVT0AbAHWzKcmSVI3Br376w/au+kfBl4AvLuqtsxzmSvovZr4fyd5CXAT8Dbg2Kq6t/X5Dj/+HcwS4J6++be3trnaJUljst9QSXII8IX2UMn5BsnMZa4CfqOqtib5ID8+1QVAVVWSvd40OV9J1tM7dcbxxx/f1ddKkmbY7+mvqnoc+FE7bdWF7cD2qtraxq+gFzLfbae1aH/va9N3AMv65l/a2uZqn20dLqqq1VW1evHixR2thiRppkGvqfwAuDXJxe1OrAuTXDifBVbVd4B7krygNZ0M3EHvYZXTd3CtA65sw5uBs9pdYCcBD7XTZNcApyQ5ql2gP6W1SZLGZNDHtHymfbryG8AnkxwO3A28iV7AXZ7kbOBb/PglYFcBrwamgEdaX6pqV5L3Aje2fu+pql0d1ihJepL2GSpJjq+qb1dVp8/5qqqb6T1Of6aTZ+lbwDlzfM9GYGOXtUmS5m9/p78+Oz2Q5NNDrkWSNOH2FyrpG37eMAuRJE2+/YVKzTEsSdJe9neh/iVJHqZ3xPL0Nkwbr6p61lCrkyRNlH2GSlUdMqpCJEmT78m8T0WSpH0yVCRJnTFUJEmdMVQkSZ0xVCRJnTFUJEmdMVQkSZ0xVCRJnTFUJEmdMVQkSZ0xVCRJnTFUJEmdMVQkSZ0xVCRJnTFUJEmdMVQkSZ0ZW6gkOSTJV5J8ro2vSLI1yVSSy5Ic3tqf2san2vTlfd9xXmv/epJTx7MmkqRp4zxSeRtwZ9/4+4ELqur5wAPA2a39bOCB1n5B60eSE4AzgRcCa4APJ/FNlZI0RmMJlSRLgdcAH2vjAV4JXNG6bALOaMNr2zht+smt/1rg0qp6tKq+AUwBJ45mDSRJsxnXkcofAu8AftTGnw08WFW72/h2YEkbXgLcA9CmP9T672mfZR5J0hiMPFSS/DJwX1XdNMJlrk+yLcm2nTt3jmqxknTQGceRysuB05N8E7iU3mmvDwKLkhza+iwFdrThHcAygDb9SOD+/vZZ5nmCqrqoqlZX1erFixd3uzaSpD1GHipVdV5VLa2q5fQutH+xqt4AXAe8tnVbB1zZhje3cdr0L1ZVtfYz291hK4CVwA0jWg1J0iwO3X+XkXkncGmS3wO+Alzc2i8GPpFkCthFL4ioqtuTXA7cAewGzqmqx0dftiRp2lhDpar+GvjrNnw3s9y9VVX/DPzqHPOfD5w/vAolSU/GQjpS0RyWn/v5sS37m+97zdiWLWny+JgWSVJnDBVJUmc8/aV9GtepN0+7SZPJIxVJUmcMFUlSZwwVSVJnDBVJUmcMFUlSZwwVSVJnDBVJUmcMFUlSZwwVSVJn/EW9FiQfoilNJo9UJEmdMVQkSZ0xVCRJnTFUJEmdMVQkSZ0xVCRJnTFUJEmdGXmoJFmW5LokdyS5PcnbWvvRSbYkuav9Paq1J8mFSaaS3JJkVd93rWv970qybtTrIkl6onEcqewGfruqTgBOAs5JcgJwLnBtVa0Erm3jAKcBK9tnPfAR6IUQsAF4GXAisGE6iCRJ4zHyUKmqe6vqy234+8CdwBJgLbCpddsEnNGG1wKXVM/1wKIkxwGnAluqaldVPQBsAdaMcFUkSTOM9ZpKkuXAzwFbgWOr6t426TvAsW14CXBP32zbW9tc7ZKkMRlbqCR5BvBp4O1V9XD/tKoqoDpc1vok25Js27lzZ1dfK0maYSyhkuQweoHyyar6TGv+bjutRft7X2vfASzrm31pa5urfS9VdVFVra6q1YsXL+5uRSRJTzCOu78CXAzcWVUf6Ju0GZi+g2sdcGVf+1ntLrCTgIfaabJrgFOSHNUu0J/S2iRJYzKOR9+/HPg14NYkN7e2dwHvAy5PcjbwLeB1bdpVwKuBKeAR4E0AVbUryXuBG1u/91TVrtGsgiRpNiMPlar6WyBzTD55lv4FnDPHd20ENnZXnSTpQPiSLmmGcb0gzJeD6SeBj2mRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xgdKSgvEuB5kCT7MUt3xSEWS1BlDRZLUGUNFktQZQ0WS1BlDRZLUGUNFktQZbymWNLbbmb2V+SfPxB+pJFmT5OtJppKcO+56JOlgNtGhkuQQ4I+B04ATgNcnOWG8VUnSwWvST3+dCExV1d0ASS4F1gJ3jLUqSQPxtNtPnkkPlSXAPX3j24GXjakWSRPCR+IMz6SHykCSrAfWt9EfJPn6PL/qGOB73VQ1MtY8fJNWL1jzqOxVc94/pkoGN9d2fu4gM096qOwAlvWNL21tT1BVFwEXHejCkmyrqtUH+j2jZM3DN2n1gjWPysFY80RfqAduBFYmWZHkcOBMYPOYa5Kkg9ZEH6lU1e4kbwWuAQ4BNlbV7WMuS5IOWhMdKgBVdRVw1YgWd8Cn0MbAmodv0uoFax6Vg67mVFVXhUiSDnKTfk1FkrSAGCqz2N+jX5I8NcllbfrWJMtHX+UT6tlfvW9MsjPJze3zn8dR54yaNia5L8ltc0xPkgvbOt2SZNWoa5xRz/7qfUWSh/q28btHXeMsNS1Lcl2SO5LcnuRts/RZaNt5kJoX1LZO8rQkNyT5aqv5f8zSZ8HsMwasd/77jKry0/ehd8H/H4DnAYcDXwVOmNHnLcBH2/CZwGULvN43An807m07o6ZfAlYBt80x/dXA1UCAk4CtC7zeVwCfG/d2nVHTccCqNvxM4O9n+W9joW3nQWpeUNu6bbtntOHDgK3ASTP6LKR9xiD1znuf4ZHK3vY8+qWqHgOmH/3Sby2wqQ1fAZycJCOssd8g9S44VfUlYNc+uqwFLqme64FFSY4bTXV7G6DeBaeq7q2qL7fh7wN30nsKRb+Ftp0HqXlBadvuB230sPaZebF6wewzBqx33gyVvc326JeZ/1Hv6VNVu4GHgGePpLq9DVIvwH9opzeuSLJslukLzaDrtZD8QjulcHWSF467mH7tdMvP0ftXab8Fu533UTMssG2d5JAkNwP3AVuqas7tvAD2GYPUC/PcZxgqB4e/AJZX1YuBLfz4X0zqzpeB51bVS4APAZ8dcz17JHkG8Gng7VX18LjrGcR+al5w27qqHq+qf0XvqR4nJnnRuGvalwHqnfc+w1DZ2yCPftnTJ8mhwJHA/SOpbm/7rbeq7q+qR9vox4CXjqi2AzHQI3gWiqp6ePqUQvV+O3VYkmPGXBZJDqO3c/5kVX1mli4Lbjvvr+aFuq0BqupB4DpgzYxJC2mfscdc9R7IPsNQ2dsgj37ZDKxrw68Fvljt6tYY7LfeGefIT6d3nnqh2wyc1e5OOgl4qKruHXdRc0nynOlz5ElOpPf/1lh3Gq2ei4E7q+oDc3RbUNt5kJoX2rZOsjjJojb8dOBVwNdmdFsw+4xB6j2QfcbE/6K+azXHo1+SvAfYVlWb6f1H/4kkU/Qu3p65wOv9zSSnA7tbvW8cV73TknyK3l08xyTZDmygd8GQqvoovackvBqYAh4B3jSeSnsGqPe1wK8n2Q38EDhzjP/QmPZy4NeAW9v5c4B3AcfDwtzODFbzQtvWxwGb0ntp4FOAy6vqcwt1n8Fg9c57n+Ev6iVJnfH0lySpM4aKJKkzhookqTOGiiSpM4aKJKkzhookqTOGiiSpM4aKJKkz/x/Jo2x8WqFhoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_series = pd.Series(norms)\n",
    "norm_series.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Patterns in vector lengths?\n",
    "\n",
    "Fill in the missing code below to add a column called `norm` containing the length of each movie's embedding to our DataFrame containing all movies (`all_movies_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 2, \"questionId\": \"3.2_NormColumn\", \"interactionType\": 1, \"failureMessage\": \"Expected dataframe `all_movies_df` to have column norm\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> Expected dataframe `all_movies_df` to have column norm"
      ],
      "text/plain": [
       "Incorrect: Expected dataframe `all_movies_df` to have column norm"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Your code goes here. Add the column \"norm\" to our movies dataframe.\n",
    "part3.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 4, \"questionId\": \"3.2_NormColumn\", \"interactionType\": 3, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "all_movies_df['norm'] = norms\n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "all_movies_df['norm'] = norms\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#part3.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to see the movies with the largest and smallest embedding vectors. Do you see a pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>24994</td>\n",
       "      <td>Carry On Teacher</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Carry On Teacher</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20020</th>\n",
       "      <td>20020</td>\n",
       "      <td>Consuming Spirits</td>\n",
       "      <td>Animation|Comedy|Drama|Mystery</td>\n",
       "      <td>Consuming Spirits</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24549</th>\n",
       "      <td>24549</td>\n",
       "      <td>Dream Boy</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>Dream Boy</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24543</th>\n",
       "      <td>24543</td>\n",
       "      <td>Demoted</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Demoted</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24539</th>\n",
       "      <td>24539</td>\n",
       "      <td>Love Sick Love</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Love Sick Love</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId              title                          genres  \\\n",
       "24994    24994   Carry On Teacher                          Comedy   \n",
       "20020    20020  Consuming Spirits  Animation|Comedy|Drama|Mystery   \n",
       "24549    24549          Dream Boy                   Drama|Romance   \n",
       "24543    24543            Demoted                          Comedy   \n",
       "24539    24539     Love Sick Love                        Thriller   \n",
       "\n",
       "                     key  year  n_ratings  mean_rating  norm  \n",
       "24994   Carry On Teacher  1959          1          3.5   0.0  \n",
       "20020  Consuming Spirits  2012          1          NaN   0.0  \n",
       "24549          Dream Boy  2008          1          3.5   0.0  \n",
       "24543            Demoted  2011          1          3.5   0.0  \n",
       "24539     Love Sick Love  2013          1          NaN   0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "# Movies with the smallest embeddings (as measured by L2 norm)\n",
    "all_movies_df.sort_values(by='norm').head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>6373</td>\n",
       "      <td>From Justin to Kelly</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>From Justin to Kelly</td>\n",
       "      <td>2003</td>\n",
       "      <td>426</td>\n",
       "      <td>0.983831</td>\n",
       "      <td>3.396398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>Dumb &amp; Dumber (Dumb and Dumber)</td>\n",
       "      <td>Adventure|Comedy</td>\n",
       "      <td>Dumb &amp; Dumber (Dumb and Dumber)</td>\n",
       "      <td>1994</td>\n",
       "      <td>32085</td>\n",
       "      <td>2.950768</td>\n",
       "      <td>3.321958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>4679</td>\n",
       "      <td>Glitter</td>\n",
       "      <td>Drama|Musical|Romance</td>\n",
       "      <td>Glitter</td>\n",
       "      <td>2001</td>\n",
       "      <td>685</td>\n",
       "      <td>1.121705</td>\n",
       "      <td>3.313496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>6477</td>\n",
       "      <td>Gigli</td>\n",
       "      <td>Comedy|Crime|Romance</td>\n",
       "      <td>Gigli</td>\n",
       "      <td>2003</td>\n",
       "      <td>701</td>\n",
       "      <td>1.168390</td>\n",
       "      <td>3.258397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>9754</td>\n",
       "      <td>Son of the Mask</td>\n",
       "      <td>Adventure|Children|Comedy|Fantasy</td>\n",
       "      <td>Son of the Mask</td>\n",
       "      <td>2005</td>\n",
       "      <td>467</td>\n",
       "      <td>1.254525</td>\n",
       "      <td>3.245531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                            title  \\\n",
       "6373     6373             From Justin to Kelly   \n",
       "228       228  Dumb & Dumber (Dumb and Dumber)   \n",
       "4679     4679                          Glitter   \n",
       "6477     6477                            Gigli   \n",
       "9754     9754                  Son of the Mask   \n",
       "\n",
       "                                 genres                              key  \\\n",
       "6373                    Musical|Romance             From Justin to Kelly   \n",
       "228                    Adventure|Comedy  Dumb & Dumber (Dumb and Dumber)   \n",
       "4679              Drama|Musical|Romance                          Glitter   \n",
       "6477               Comedy|Crime|Romance                            Gigli   \n",
       "9754  Adventure|Children|Comedy|Fantasy                  Son of the Mask   \n",
       "\n",
       "      year  n_ratings  mean_rating      norm  \n",
       "6373  2003        426     0.983831  3.396398  \n",
       "228   1994      32085     2.950768  3.321958  \n",
       "4679  2001        685     1.121705  3.313496  \n",
       "6477  2003        701     1.168390  3.258397  \n",
       "9754  2005        467     1.254525  3.245531  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movies with the largest embeddings\n",
    "all_movies_df.sort_values(by='norm', ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cell below for some speculation about what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"data\": {\"learnTutorialId\": -1, \"trace\": \"\", \"outcomeType\": 4, \"questionId\": \"3.3_NormPatterns\", \"interactionType\": 3, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"valueTowardsCompletion\": 0.0, \"learnToolsVersion\": \"0.2.3-alpha.2\"}, \"jupyterEvent\": \"custom.exercise_interaction\"}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> TODO"
      ],
      "text/plain": [
       "Solution: TODO"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#part3.c.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`</exercise>`\n",
    "\n",
    "# Scratch space\n",
    "\n",
    "## Look up your favourite movie and judge how legit the similar titles are! \n",
    "\n",
    "## multiple positive movies\n",
    "\n",
    "What movies do you get if you combine x + y? What movies lie between x and y?\n",
    "\n",
    "## cos distance vs. euclidean\n",
    "\n",
    "looking at different magnitudes of movies\n",
    "\n",
    "-----------------\n",
    "\n",
    "## analogies? Not sure if better to do in an exercise, or in the body of lesson. Or both.\n",
    "\n",
    "## clustering...?\n",
    "\n",
    "## exploring more gensim methods\n",
    "\n",
    "`doesnt_match`, \n",
    "\n",
    "## Exploring individual dimensions of the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19246</th>\n",
       "      <td>19246</td>\n",
       "      <td>The Angels' Share</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>The Angels' Share</td>\n",
       "      <td>2012</td>\n",
       "      <td>105</td>\n",
       "      <td>3.676768</td>\n",
       "      <td>0.314971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>19299</td>\n",
       "      <td>The Queen of Versailles</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>The Queen of Versailles</td>\n",
       "      <td>2012</td>\n",
       "      <td>144</td>\n",
       "      <td>3.640288</td>\n",
       "      <td>0.359256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17047</th>\n",
       "      <td>17047</td>\n",
       "      <td>Mildred Pierce</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Mildred Pierce (2011)</td>\n",
       "      <td>2011</td>\n",
       "      <td>120</td>\n",
       "      <td>3.712389</td>\n",
       "      <td>0.379933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>9044</td>\n",
       "      <td>Diggstown</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Diggstown</td>\n",
       "      <td>1992</td>\n",
       "      <td>107</td>\n",
       "      <td>3.426471</td>\n",
       "      <td>0.381574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19341</th>\n",
       "      <td>19341</td>\n",
       "      <td>Celeste and Jesse Forever (Celeste &amp; Jesse For...</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>Celeste and Jesse Forever (Celeste &amp; Jesse For...</td>\n",
       "      <td>2012</td>\n",
       "      <td>109</td>\n",
       "      <td>3.364078</td>\n",
       "      <td>0.403814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                              title  \\\n",
       "19246    19246                                  The Angels' Share   \n",
       "19299    19299                            The Queen of Versailles   \n",
       "17047    17047                                     Mildred Pierce   \n",
       "9044      9044                                          Diggstown   \n",
       "19341    19341  Celeste and Jesse Forever (Celeste & Jesse For...   \n",
       "\n",
       "                     genres  \\\n",
       "19246          Comedy|Drama   \n",
       "19299           Documentary   \n",
       "17047                 Drama   \n",
       "9044                  Drama   \n",
       "19341  Comedy|Drama|Romance   \n",
       "\n",
       "                                                     key  year  n_ratings  \\\n",
       "19246                                  The Angels' Share  2012        105   \n",
       "19299                            The Queen of Versailles  2012        144   \n",
       "17047                              Mildred Pierce (2011)  2011        120   \n",
       "9044                                           Diggstown  1992        107   \n",
       "19341  Celeste and Jesse Forever (Celeste & Jesse For...  2012        109   \n",
       "\n",
       "       mean_rating      norm  \n",
       "19246     3.676768  0.314971  \n",
       "19299     3.640288  0.359256  \n",
       "17047     3.712389  0.379933  \n",
       "9044      3.426471  0.381574  \n",
       "19341     3.364078  0.403814  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_movies_df[all_movies_df.n_ratings >= threshold].sort_values(by='norm').head(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "learntools_metadata": {
   "lesson_index": 2,
   "type": "exercise"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
