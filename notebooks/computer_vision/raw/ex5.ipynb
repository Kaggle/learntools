{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In these exercises, you'll build a custom convnet with performance competitive to the VGG16 model from Lesson 1.\n",
    "\n",
    "Get started by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.computer_vision.ex5 import *\n",
    "\n",
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_keras\n",
    "from tf_keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "\n",
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design a Convnet #\n",
    "\n",
    "Let's design a convolutional network with a block architecture like we saw in the tutorial. The model from the example had three blocks, each with a single convolutional layer. Its performance on the \"Car or Truck\" problem was okay, but far from what the pretrained VGG16 could achieve. It might be that our simple network lacks the ability to extract sufficiently complex features. We could try improving the model either by adding more blocks or by adding convolutions to the blocks we have.\n",
    "\n",
    "Let's go with the second approach. We'll keep the three block structure, but increase the number of `Conv2D` layer in the second block to two, and in the third block to three.\n",
    "\n",
    "<figure>\n",
    "<!-- <img src=\"./images/2-convmodel-2.png\" width=\"250\" alt=\"Diagram of a convolutional model.\"> -->\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/Vko6nCK.png\" width=\"250\" alt=\"Diagram of a convolutional model.\">\n",
    "</figure>\n",
    "\n",
    "# 1) Define Model #\n",
    "\n",
    "Given the diagram above, complete the model by defining the layers of the third block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from tf_keras import layers\n",
    "\n",
    "model = tf_keras.Sequential([\n",
    "    # Block One\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n",
    "                  input_shape=[128, 128, 3]),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Three\n",
    "    # YOUR CODE HERE\n",
    "    # ____,\n",
    "\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "import tf_keras\n",
    "from tf_keras import layers\n",
    "\n",
    "model = tf_keras.Sequential([\n",
    "    # Block One\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n",
    "                  input_shape=[128, 128, 3]),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Three\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Compile #\n",
    "\n",
    "To prepare for training, compile the model with an appropriate loss and accuracy metric for the \"Car or Truck\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf_keras.optimizers.Adam(epsilon=0.01),\n",
    "    # YOUR CODE HERE: Add loss and metric\n",
    ")\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf_keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test the performance of this new model. First run this cell to fit the model to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now run the cell below to plot the loss and metric curves for this training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Train the Model #\n",
    "\n",
    "How would you interpret these training curves? Did this model improve upon the model from the tutorial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# View the solution (Run this code cell to receive credit!)\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n",
    "\n",
    "These exercises showed you how to design a custom convolutional network to solve a specific classification problem. Though most models these days will be built on top of a pretrained base, it certain circumstances a smaller custom convnet might still be preferable -- such as with a smaller or unusual dataset or when computing resources are very limited. As you saw here, for certain problems they can perform just as well as a pretrained model.\n",
    "\n",
    "# Keep Going #\n",
    "\n",
    "Continue on to [**Lesson 6**](#$NEXT_NOTEBOOK_URL$), where you'll learn a widely-used technique that can give a boost to your training data: **data augmentation**."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
