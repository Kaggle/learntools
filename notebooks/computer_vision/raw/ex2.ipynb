{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In this exercise, you'll work on building some intuition around feature extraction. First, we'll walk through the example we did in the tutorial again, but this time, with a kernel you choose yourself. We've mostly been working with images in this course, but what's behind all of the operations we're learning about is mathematics. So, we'll also take a look at how these feature maps can be represented instead as arrays of numbers and what effect convolution with a kernel will have on them.\n",
    "\n",
    "Run the cell below to get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.computer_vision.ex2 import *\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Transformations #\n",
    "\n",
    "The next few exercises walk through feature extraction just like the example in the tutorial. Run the following cell to load an image we'll use for the next few exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../input/computer-vision-resources/car_illus.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.io.decode_jpeg(image, channels=1)\n",
    "image = tf.image.resize(image, size=[400, 400])\n",
    "\n",
    "img = tf.squeeze(image).numpy()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this cell to see some standard kernels used in image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learntools.computer_vision.visiontools as visiontools\n",
    "from learntools.computer_vision.visiontools import edge, bottom_sobel, emboss, sharpen\n",
    "\n",
    "kernels = [edge, bottom_sobel, emboss, sharpen]\n",
    "names = [\"Edge Detect\", \"Bottom Sobel\", \"Emboss\", \"Sharpen\"]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, (kernel, name) in enumerate(zip(kernels, names)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    visiontools.show_kernel(kernel)\n",
    "    plt.title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Define Kernel #\n",
    "\n",
    "Use the next code cell to define a kernel. You have your choice of what kind of kernel to apply. One thing to keep in mind is that the *sum* of the numbers in the kernel determines how bright the final image is. Generally, you should try to keep the sum of the numbers between 0 and 1 (though that's not required for a correct answer).\n",
    "\n",
    "In general, a kernel can have any number of rows and columns. For this exercise, let's use a $3 \\times 3$ kernel, which often gives the best results. Define a kernel with `tf.constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Define a kernel with 3 rows and 3 columns.\n",
    "kernel = tf.constant([\n",
    "    #____,\n",
    "])\n",
    "# Uncomment to view kernel\n",
    "# visiontools.show_kernel(kernel)\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "kernel = np.array([\n",
    "    [-2, -1, 0],\n",
    "    [-1, 1, 1],\n",
    "    [0, 1, 2],\n",
    "])\n",
    "q_1.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "kernel = tf.constant([\n",
    "    'abc'\n",
    "])\n",
    "q_1.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "kernel = tf.constant([0, 1, 2])\n",
    "q_1.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "kernel = tf.constant([\n",
    "    [-2, -1, 0],\n",
    "    [-1, 1, 1],\n",
    "    [0, 1, 2],\n",
    "])\n",
    "visiontools.show_kernel(kernel)\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do the first step of feature extraction, the filtering step. First run this cell to do some reformatting for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat for batch compatibility.\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Apply Convolution #\n",
    "\n",
    "Now we'll apply the kernel to the image by a convolution. The *layer* in Keras that does this is `layers.Conv2D`. What is the *backend function* in TensorFlow that performs the same operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Give the TensorFlow convolution function (without arguments)\n",
    "conv_fn = ____\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "conv_fn = 'abc'\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "conv_fn = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    strides=1, # or (1, 1)\n",
    "    padding='SAME',\n",
    ")\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "conv_fn = tf.nn.conv2d\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've got the correct answer, run this next cell to execute the convolution and see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filter = conv_fn(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    strides=1, # or (1, 1)\n",
    "    padding='SAME',\n",
    ")\n",
    "\n",
    "plt.imshow(\n",
    "    # Reformat for plotting\n",
    "    tf.squeeze(image_filter)\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see how the kernel you chose relates to the feature map it produced?\n",
    "\n",
    "# 3) Apply ReLU #\n",
    "\n",
    "Now detect the feature with the ReLU function. In Keras, you'll usually use this as the activation function in a `Conv2D` layer. What is the *backend function* in TensorFlow that does the same thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Give the TensorFlow ReLU function (without arguments)\n",
    "relu_fn = ____\n",
    "\n",
    "# Check your answer\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "relu_fn = 'abc'\n",
    "q_3.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "relu_fn = tf.nn.relu(image_filter)\n",
    "q_3.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "relu_fn = tf.nn.relu\n",
    "q_3.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've got the solution, run this cell to detect the feature with ReLU and see the result!\n",
    "\n",
    "The image you see below is the feature map produced by the kernel you chose. If you like, experiment with some of the other suggested kernels above, or, try to invent one that will extract a certain kind of feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detect = relu_fn(image_filter)\n",
    "\n",
    "plt.imshow(\n",
    "    # Reformat for plotting\n",
    "    tf.squeeze(image_detect)\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tutorial, our discussion of kernels and feature maps was mainly visual. We saw the effect of `Conv2D` and `ReLU` by observing how they transformed some example images.\n",
    "\n",
    "But the operations in a convolutional network (like in all neural networks) are usually defined through mathematical functions, through a computation on numbers. In the next exercise, we'll take a moment to explore this point of view.\n",
    "\n",
    "Let's start by defining a simple array to act as an image, and another array to act as the kernel. Run the following cell to see these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sympy is a python library for symbolic mathematics. It has a nice\n",
    "# pretty printer for matrices, which is all we'll use it for.\n",
    "import sympy\n",
    "sympy.init_printing()\n",
    "from IPython.display import display\n",
    "\n",
    "image = np.array([\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, -1],\n",
    "    [1, -1],\n",
    "])\n",
    "\n",
    "display(sympy.Matrix(image))\n",
    "display(sympy.Matrix(kernel))\n",
    "# Reformat for Tensorflow\n",
    "image = tf.cast(image, dtype=tf.float32)\n",
    "image = tf.reshape(image, [1, *image.shape, 1])\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Observe Convolution on a Numerical Matrix #\n",
    "\n",
    "\n",
    "What do you see? The image is simply a long vertical line on the left and a short horizontal line on the lower right. What about the kernel? What effect do you think it will have on this image? After you've thought about it, run the next cell for the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# View the solution (Run this code cell to receive credit!)\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it out. Run the next cell to apply convolution and ReLU to the image and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    strides=1,\n",
    "    padding='VALID',\n",
    ")\n",
    "image_detect = tf.nn.relu(image_filter)\n",
    "\n",
    "# The first matrix is the image after convolution, and the second is\n",
    "# the image after ReLU.\n",
    "display(sympy.Matrix(tf.squeeze(image_filter).numpy()))\n",
    "display(sympy.Matrix(tf.squeeze(image_detect).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the result what you expected?\n",
    "\n",
    "# Conclusion #\n",
    "\n",
    "In this lesson, you learned about the first two operations a convolutional classifier uses for feature extraction: **filtering** an image with a **convolution** and **detecting** the feature with the **rectified linear unit**. \n",
    "\n",
    "# Keep Going #\n",
    "\n",
    "Move on to [**Lesson 3**](#$NEXT_NOTEBOOK_URL$) to learn the final operation: **condensing** the feature map with **maximum pooling**!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
