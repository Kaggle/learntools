{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rough-daughter",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "Run this cell to set everything up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.time_series.ex4 import *\n",
    "\n",
    "# Setup notebook\n",
    "from pathlib import Path\n",
    "from learntools.time_series.style import *  # plot style settings\n",
    "from learntools.time_series.utils import plot_lags, make_lags, make_leads\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "\n",
    "\n",
    "comp_dir = Path('../input/store-sales-time-series-forecasting')\n",
    "\n",
    "store_sales = pd.read_csv(\n",
    "    comp_dir / 'train.csv',\n",
    "    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'sales': 'float32',\n",
    "        'onpromotion': 'uint32',\n",
    "    },\n",
    "    parse_dates=['date'],\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "store_sales['date'] = store_sales.date.dt.to_period('D')\n",
    "store_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n",
    "\n",
    "family_sales = (\n",
    "    store_sales\n",
    "    .groupby(['family', 'date'])\n",
    "    .mean() \n",
    "    .unstack('family')\n",
    "    .loc['2017', ['sales', 'onpromotion']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-diagram",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------\n",
    "\n",
    "Not every product family has sales showing cyclic behavior, and neither does the series of average sales. Sales of school and office supplies, however, show patterns of growth and decay not well characterized by trend or seasons. In this question and the next, you'll model cycles in sales of school and office supplies using lag features.\n",
    "\n",
    "Trend and seasonality will both create serial dependence that shows up in correlograms and lag plots. To isolate any purely *cyclic* behavior, we'll start by deseasonalizing the series. Use the code in the next cell to deseasonalize *Supply Sales*. We'll store the result in a variable `y_deseason`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_sales = family_sales.loc(axis=1)[:, 'SCHOOL AND OFFICE SUPPLIES']\n",
    "y = supply_sales.loc[:, 'sales'].squeeze()\n",
    "\n",
    "fourier = CalendarFourier(freq='M', order=4)\n",
    "dp = DeterministicProcess(\n",
    "    constant=True,\n",
    "    index=y.index,\n",
    "    order=1,\n",
    "    seasonal=True,\n",
    "    drop=True,\n",
    "    additional_terms=[fourier],\n",
    ")\n",
    "X_time = dp.in_sample()\n",
    "X_time['NewYearsDay'] = (X_time.index.dayofyear == 1)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_time, y)\n",
    "y_deseason = y - model.predict(X_time)\n",
    "y_deseason.name = 'sales_deseasoned'\n",
    "\n",
    "ax = y_deseason.plot()\n",
    "ax.set_title(\"Sales of School and Office Supplies (deseasonalized)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-credit",
   "metadata": {},
   "source": [
    "Does this deseasonalized series show cyclic patterns? To confirm our intuition, we can try to isolate cyclic behavior using a moving-average plot just like we did with trend. The idea is to choose a window long enough to smooth over short-term seasonality, but short enough to still preserve the cycles.\n",
    "\n",
    "# 1) Plotting cycles\n",
    "\n",
    "Create a seven-day moving average from `y`, the series of supply sales. Use a centered window, but don't set the `min_periods` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "y_ma = ____\n",
    "\n",
    "\n",
    "# Plot\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#ax = y_ma.plot()\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#ax.set_title(\"Seven-Day Moving Average\");\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_ma = y.rolling(7, center=True).mean()\n",
    "\n",
    "ax = y_ma.plot()\n",
    "ax.set_title(\"Seven-Day Moving Average\");\n",
    "\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-classics",
   "metadata": {},
   "source": [
    "Do you see how the moving average plot resembles the plot of the deseasonalized series? In both, we can see cyclic behavior indicated.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Let's examine our deseasonalized series for serial dependence. Take a look at the partial autocorrelation correlogram and lag plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(y_deseason, lags=8);\n",
    "plot_lags(y_deseason, lags=8, nrows=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-commissioner",
   "metadata": {},
   "source": [
    "# 2) Examine serial dependence in *Store Sales*\n",
    "\n",
    "Are any of the lags significant according to the correlogram? Does the lag plot suggest any relationships that weren't apparent from the correlogram?\n",
    "\n",
    "After you've thought about your answer, run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-argentina",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Recall from the tutorial that a *leading indicator* is a series whose values at one time can be used to predict the target at a future time -- a leading indicator provides \"advance notice\" of changes in the target.\n",
    "\n",
    "The competition dataset includes a time series that could potentially be useful as a leading indicator -- the `onpromotion` series, which contains the number of items on a special promotion that day. Since the company itself decides when to do a promotion, there's no worry about \"lookahead leakage\"; we could use Tuesday's `onpromotion` value to forecast sales on Monday, for instance.\n",
    "\n",
    "Use the next cell to examine leading and lagging values for `onpromotion` plotted against sales of school and office supplies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "onpromotion = supply_sales.loc[:, 'onpromotion'].squeeze().rename('onpromotion')\n",
    "\n",
    "# Drop days without promotions\n",
    "plot_lags(x=onpromotion.loc[onpromotion > 1], y=y_deseason.loc[onpromotion > 1], lags=3, leads=3, nrows=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-halloween",
   "metadata": {},
   "source": [
    "# 3) Examine time series features\n",
    "\n",
    "Does it appear that either leading or lagging values of `onpromotion` could be useful as a feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-explanation",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "# 4) Create time series features\n",
    "\n",
    "Create the features indicated in the solution to Question 3. If no features from that series would be useful, use an empty dataframe `pd.DataFrame()` as your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Make features from `y_deseason`\n",
    "X_lags = ____\n",
    "\n",
    "# YOUR CODE HERE: Make features from `onpromotion`\n",
    "# You may want to use `pd.concat`\n",
    "X_promo = ____\n",
    "\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#X = pd.concat([X_lags, X_promo], axis=1)\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#y, X = y.align(X, join='inner')\n",
    "\n",
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X_lags = make_lags(y_deseason, lags=2)\n",
    "\n",
    "X_promo = pd.concat([\n",
    "    make_lags(onpromotion, lags=1),\n",
    "    onpromotion,\n",
    "    make_leads(onpromotion, leads=1),\n",
    "], axis=1)\n",
    "\n",
    "X = pd.concat([X_time, X_lags, X_promo], axis=1).dropna()\n",
    "y, X = y.align(X, join='inner')\n",
    "\n",
    "q_4.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X_lags = make_lags(y_deseason, lags=1)\n",
    "\n",
    "X_promo = pd.concat([\n",
    "    make_lags(onpromotion, lags=2),\n",
    "    onpromotion,\n",
    "    make_leads(onpromotion, leads=1),\n",
    "], axis=1)\n",
    "\n",
    "X = pd.concat([X_time, X_lags, X_promo], axis=1).dropna()\n",
    "y, X = y.align(X, join='inner')\n",
    "\n",
    "q_4.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X_lags = make_lags(y_deseason, lags=1)\n",
    "\n",
    "X_promo = pd.concat([\n",
    "    make_lags(onpromotion, lags=1),\n",
    "#    onpromotion,\n",
    "    make_leads(onpromotion, leads=1),\n",
    "], axis=1)\n",
    "\n",
    "X = pd.concat([X_time, X_lags, X_promo], axis=1).dropna()\n",
    "y, X = y.align(X, join='inner')\n",
    "\n",
    "q_4.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X_lags = pd.DataFrame()\n",
    "\n",
    "X_promo = pd.concat([\n",
    "    make_lags(onpromotion, lags=1),\n",
    "    onpromotion,\n",
    "    make_leads(onpromotion, leads=1),\n",
    "], axis=1)\n",
    "\n",
    "X = pd.concat([X_time, X_lags, X_promo], axis=1).dropna()\n",
    "y, X = y.align(X, join='inner')\n",
    "\n",
    "q_4.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X_lags = make_lags(y_deseason, lags=1)\n",
    "\n",
    "X_promo = pd.concat([\n",
    "    make_lags(onpromotion, lags=1),\n",
    "    onpromotion,\n",
    "    make_leads(onpromotion, leads=1),\n",
    "], axis=1)\n",
    "\n",
    "X = pd.concat([X_time, X_lags, X_promo], axis=1).dropna()\n",
    "y, X = y.align(X, join='inner')\n",
    "\n",
    "q_4.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-negotiation",
   "metadata": {},
   "source": [
    "Use the code in the next cell if you'd like to see predictions from the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=30, shuffle=False)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "y_fit = pd.Series(model.predict(X_train), index=X_train.index).clip(0.0)\n",
    "y_pred = pd.Series(model.predict(X_valid), index=X_valid.index).clip(0.0)\n",
    "\n",
    "rmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\n",
    "rmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\n",
    "print(f'Training RMSLE: {rmsle_train:.5f}')\n",
    "print(f'Validation RMSLE: {rmsle_valid:.5f}')\n",
    "\n",
    "ax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\n",
    "ax = y_fit.plot(ax=ax, label=\"Fitted\", color='C0')\n",
    "ax = y_pred.plot(ax=ax, label=\"Forecast\", color='C3')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-controversy",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Winners of Kaggle forecasting competitions have often included moving averages and other rolling statistics in their feature sets. Such features seem to be especially useful when used with GBDT algorithms like XGBoost.\n",
    "\n",
    "In Lesson 2 you learned how to compute moving averages to estimate trends. Computing rolling statistics to be used as features is similar except we need to take care to avoid lookahead leakage. First, the result should be set at the right end of the window instead of the center -- that is, we should use `center=False` (the default) in the `rolling` method. Second, the target should be lagged a step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-struggle",
   "metadata": {},
   "source": [
    "# 5) Create statistical features\n",
    "\n",
    "Edit the code in the next cell to create the following features:\n",
    "- 14-day rolling median (`median`) of lagged target\n",
    "- 7-day rolling standard deviation (`std`) of lagged target\n",
    "- 7-day sum (`sum`) of items \"on promotion\", with centered window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "# 28-day mean of lagged target\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "# YOUR CODE HERE: 14-day median of lagged target\n",
    "median_14 = ____\n",
    "# YOUR CODE HERE: 7-day rolling standard deviation of lagged target\n",
    "std_7 = ____\n",
    "# YOUR CODE HERE: 7-day sum of promotions with centered window\n",
    "promo_7 = ____\n",
    "\n",
    "\n",
    "# Check your answer\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_5.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_5.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "median_14 = y_lag.rolling(7).median()\n",
    "std_7 = y_lag.rolling(7).std()\n",
    "promo_7 = onpromo.rolling(7, center=True).sum()\n",
    "\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "median_14 = y_lag.rolling(14).median()\n",
    "std_7 = y_lag.rolling(14).std()\n",
    "promo_7 = onpromo.rolling(7, center=True).sum()\n",
    "\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "median_14 = y_lag.rolling(14).median()\n",
    "std_7 = y_lag.rolling(7).std()\n",
    "promo_7 = onpromo.rolling(14, center=True).sum()\n",
    "\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "median_14 = y_lag.rolling(14).median()\n",
    "std_7 = y_lag.rolling(7).std()\n",
    "promo_7 = onpromo.rolling(7, center=False).sum()\n",
    "\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "median_14 = y_lag.rolling(14).mean()\n",
    "std_7 = y_lag.rolling(7).std()\n",
    "promo_7 = onpromo.rolling(7, center=True).sum()\n",
    "\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "median_14 = y_lag.rolling(14).median()\n",
    "std_7 = y_lag.rolling(7).std()\n",
    "promo_7 = y_lag.rolling(7, center=True).sum()\n",
    "\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = supply_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = supply_sales.loc[:, 'onpromotion']\n",
    "\n",
    "mean_7 = y_lag.rolling(7).mean()\n",
    "median_14 = y_lag.rolling(14).median()\n",
    "std_7 = y_lag.rolling(7).std()\n",
    "promo_7 = onpromo.rolling(7, center=True).sum()\n",
    "\n",
    "q_5.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-india",
   "metadata": {},
   "source": [
    "Check out the Pandas [`Window` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/window.html) for more statistics you can compute. Also try \"exponential weighted\" windows by using `ewm` in place of `rolling`; exponential decay is often a more realistic representation of how effects propagate over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-establishment",
   "metadata": {},
   "source": [
    "# Keep Going #\n",
    "\n",
    "[**Create hybrid forecasters**](#$NEXT_NOTEBOOK_URL$) and combine the strengths of two machine learning algorithms."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
