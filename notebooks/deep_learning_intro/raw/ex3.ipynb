{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In this exercise you'll train a neural network on the *Fuel Economy* dataset and then explore the effect of the learning rate and batch size on SGD.\n",
    "\n",
    "When you're ready, run this next cell to set everything up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from learntools.deep_learning_intro.dltools import animate_sgd\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')\n",
    "\n",
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning_intro.ex3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the *Fuel Economy* dataset your task is to predict the fuel economy of an automobile given features like its type of engine or the year it was made. \n",
    "\n",
    "First load the dataset by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fuel = pd.read_csv('../input/dl-course-data/fuel.csv')\n",
    "\n",
    "X = fuel.copy()\n",
    "# Remove target\n",
    "y = X.pop('FE')\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(),\n",
    "     make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(sparse=False),\n",
    "     make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "y = np.log(y) # log transform target instead of standardizing\n",
    "\n",
    "input_shape = [X.shape[1]]\n",
    "print(\"Input shape: {}\".format(input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data if you like. Our target in this case is the `'FE'` column and the remaining columns are the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see original data\n",
    "fuel.head()\n",
    "# Uncomment to see processed features\n",
    "pd.DataFrame(X[:10,:]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to define the network we'll use for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tf_keras import layers\n",
    "\n",
    "model = tf_keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(128, activation='relu'),    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Add Loss and Optimizer\n",
    "\n",
    "Before training the network we need to define the loss and optimizer we'll use. Using the model's `compile` method, add the Adam optimizer and MAE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#____\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# missing loss\n",
    "model.compile(\n",
    "    optimizer='adam'\n",
    ")\n",
    "q_1.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# missing optimizer\n",
    "model.compile(\n",
    "    loss='mae'\n",
    ")\n",
    "q_1.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# wrong loss\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "q_1.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# wrong optimizer\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='mae'\n",
    ")\n",
    "q_1.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='MAE'\n",
    ")\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Train Model\n",
    "\n",
    "Once you've defined the model and compiled it with a loss and optimizer you're ready for training. Train the network for 200 epochs with a batch size of 128. The input data is `X` with target `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "history = ____\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Wrong arguments\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    batch_size=8,\n",
    "    epochs=4,\n",
    ")\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    batch_size=128,\n",
    "    epochs=200,\n",
    ")\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to look at the loss curves and evaluate the training. Run the cell below to get a plot of the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5. You can change this to get a different view.\n",
    "history_df.loc[5:, ['loss']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Evaluate Training\n",
    "\n",
    "If you trained the model longer, would you expect the loss to decrease further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the learning rate and the batch size, you have some control over:\n",
    "- How long it takes to train a model\n",
    "- How noisy the learning curves are\n",
    "- How small the loss becomes\n",
    "\n",
    "To get a better understanding of these two parameters, we'll look at the linear model, our ppsimplest neural network. Having only a single weight and a bias, it's easier to see what effect a change of parameter has.\n",
    "\n",
    "The next cell will generate an animation like the one in the tutorial. Change the values for `learning_rate`, `batch_size`, and `num_examples` (how many data points) and then run the cell. (It may take a moment or two.) Try the following combinations, or try some of your own:\n",
    "\n",
    "| `learning_rate` | `batch_size` | `num_examples` |\n",
    "|-----------------|--------------|----------------|\n",
    "| 0.05            | 32           | 256            |\n",
    "| 0.05            | 2            | 256            |\n",
    "| 0.05            | 128          | 256            |\n",
    "| 0.02            | 32           | 256            |\n",
    "| 0.2             | 32           | 256            |\n",
    "| 1.0             | 32           | 256            |\n",
    "| 0.9             | 4096         | 8192           |\n",
    "| 0.99            | 4096         | 8192           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Experiment with different values for the learning rate, batch size, and number of examples\n",
    "learning_rate = 0.05\n",
    "batch_size = 32\n",
    "num_examples = 256\n",
    "\n",
    "animate_sgd(\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    num_examples=num_examples,\n",
    "    # You can also change these, if you like\n",
    "    steps=50, # total training steps (batches seen)\n",
    "    true_w=3.0, # the slope of the data\n",
    "    true_b=2.0, # the bias of the data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Learning Rate and Batch Size\n",
    "\n",
    "What effect did changing these parameters have? After you've thought about it, run the cell below for some discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Going #\n",
    "\n",
    "Learn how to [**improve your model's performance**](#$NEXT_NOTEBOOK_URL$) by tuning capacity or adding an early stopping callback."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
