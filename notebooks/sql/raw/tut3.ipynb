{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Now that you can select raw data, you're ready to learn how to group your data and count things within those groups. This can help you answer questions like: \n",
    "\n",
    "* How many of each kind of fruit has our store sold?\n",
    "* How many species of animal has the vet office treated?\n",
    "\n",
    "To do this, you'll learn about three new techniques: **GROUP BY**, **HAVING** and **COUNT()**. Once again, we'll use this made-up table of information on pets. \n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-media/learn/images/fI5Pvvp.png)\n",
    "\n",
    "# COUNT()\n",
    "\n",
    "**COUNT()**, as you may have guessed from the name, returns a count of things. If you pass it the name of a column, it will return the number of entries in that column. \n",
    "\n",
    "For instance, if we **SELECT** the **COUNT()** of the `ID` column in the `pets` table, it will return 4, because there are 4 ID's in the table.\n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-media/learn/images/Eu5HkXq.png)\n",
    "\n",
    "**COUNT()** is an example of an **aggregate function**, which takes many values and returns one. (Other examples of aggregate functions include **SUM()**, **AVG()**, **MIN()**, and **MAX()**.)  As you'll notice in the picture above, aggregate functions introduce strange column names (like `f0__`).  Later in this tutorial, you'll learn how to change the name to something more descriptive.\n",
    " \n",
    "# GROUP BY\n",
    "\n",
    "\n",
    "**GROUP BY** takes the name of one or more columns, and treats all rows with the same value in that column as a single group when you apply aggregate functions like **COUNT()**.\n",
    "\n",
    "For example, say we want to know how many of each type of animal we have in the `pets` table. We can use **GROUP BY** to group together rows that have the same value in the `Animal` column, while using **COUNT()** to find out how many ID's we have in each group. \n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-media/learn/images/tqE9Eh8.png)\n",
    "\n",
    "It returns a table with three rows (one for each distinct animal).  We can see that the `pets` table contains 1 rabbit, 1 dog, and 2 cats.\n",
    "\n",
    "# GROUP BY ... HAVING\n",
    "\n",
    "**HAVING** is used in combination with **GROUP BY** to ignore groups that don't meet certain criteria. \n",
    "\n",
    "So this query, for example, will only include groups that have more than one ID in them.\n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-media/learn/images/2ImXfHQ.png)\n",
    "\n",
    "Since only one group meets the specified criterion, the query will return a table with only one row. \n",
    "\n",
    "# Example: Which Hacker News comments generated the most discussion?\n",
    "\n",
    "Ready to see an example on a real dataset? The Hacker News dataset contains information on stories and comments from the Hacker News social networking site. \n",
    "\n",
    "We'll work with the `comments` table and begin by printing the first few rows.  (_We have hidden the corresponding code. To take a peek, click on the \"Code\" button below._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"comments\" table\n",
    "table_ref = dataset_ref.table(\"comments\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"comments\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the table to see which comments generated the most replies.  Since:\n",
    "- the `parent` column indicates the comment that was replied to, and \n",
    "- the `id` column has the unique ID used to identify each comment, \n",
    "\n",
    "we can **GROUP BY** the `parent` column and **COUNT()** the `id` column in order to figure out the number of comments that were made as responses to a specific comment.  (_This might not make sense immediately -- take your time here to ensure that everything is clear!_)\n",
    "\n",
    "Furthermore, since we're only interested in popular comments, we'll look at comments with more than ten replies.  So, we'll only return groups **HAVING** more than ten ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select comments that received more than 10 replies\n",
    "query_popular = \"\"\"\n",
    "                SELECT parent, COUNT(id)\n",
    "                FROM `bigquery-public-data.hacker_news.comments`\n",
    "                GROUP BY parent\n",
    "                HAVING COUNT(id) > 10\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our query is ready, let's run it and store the results in a pandas DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(query_popular, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and convert the results to a pandas DataFrame\n",
    "popular_comments = query_job.to_dataframe()\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "popular_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the `popular_comments` DataFrame corresponds to a comment that received more than ten replies.  For instance, the comment with ID `801208` received `56` replies.\n",
    "\n",
    "# Aliasing and other improvements\n",
    "\n",
    "A couple hints to make your queries even better:\n",
    "- The column resulting from `COUNT(id)` was called `f0__`. That's not a very descriptive name. You can change the name by adding `AS NumPosts` after you specify the aggregation. This is called **aliasing**, and it will be covered in more detail in an upcoming lesson.\n",
    "- If you are ever unsure what to put inside the **COUNT()** function, you can do `COUNT(1)` to count the rows in each group. Most people find it especially readable, because we know it's not focusing on other columns. It also scans less data than if supplied column names (making it faster and using less of your data access quota).\n",
    "\n",
    "Using these tricks, we can rewrite our query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version of earlier query, now with aliasing & improved readability\n",
    "query_improved = \"\"\"\n",
    "                 SELECT parent, COUNT(1) AS NumPosts\n",
    "                 FROM `bigquery-public-data.hacker_news.comments`\n",
    "                 GROUP BY parent\n",
    "                 HAVING COUNT(1) > 10\n",
    "                 \"\"\"\n",
    "\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(query_improved, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and convert the results to a pandas DataFrame\n",
    "improved_df = query_job.to_dataframe()\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "improved_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the data you want, and it has descriptive names. That's good style.\n",
    "\n",
    "# Note on using **GROUP BY**\n",
    "\n",
    "Note that because it tells SQL how to apply aggregate functions (like **COUNT()**), it doesn't make sense to use **GROUP BY** without an aggregate function.  Similarly, if you have any **GROUP BY** clause, then all variables must be passed to either a\n",
    "1. **GROUP BY** command, or\n",
    "2. an aggregation function.\n",
    "\n",
    "Consider the query below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_good = \"\"\"\n",
    "             SELECT parent, COUNT(id)\n",
    "             FROM `bigquery-public-data.hacker_news.comments`\n",
    "             GROUP BY parent\n",
    "             \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are two variables: `parent` and `id`. \n",
    "- `parent` was passed to a **GROUP BY** command (in `GROUP BY parent`), and \n",
    "- `id` was passed to an aggregate function (in `COUNT(id)`).\n",
    "\n",
    "And this query won't work, because the `author` column isn't passed to an aggregate function or a **GROUP BY** clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bad = \"\"\"\n",
    "            SELECT author, parent, COUNT(id)\n",
    "            FROM `bigquery-public-data.hacker_news.comments`\n",
    "            GROUP BY parent\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If make this error, you'll get the error message `SELECT list expression references column (column's name) which is neither grouped nor aggregated at`.\n",
    "\n",
    "# Your turn\n",
    "\n",
    "These aggregations let you write much more interesting queries. Try it yourself with **[these coding exercises](#$NEXT_NOTEBOOK_URL$)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
