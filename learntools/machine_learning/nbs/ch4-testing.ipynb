{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "So far, you have loaded your data and reviewed it with the following code. Run this cell to set up your coding environment where the previous step left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predictions: [ 208500.  181500.  223500.  140000.  250000.]\n",
      "Actual target values for those homes: [208500, 181500, 223500, 140000, 250000]\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../input/house-prices-advanced-regression-techniques/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "y = home_data.SalePrice\n",
    "predictor_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[predictor_columns]\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor()\n",
    "# Fit Model\n",
    "iowa_model.fit(X, y)\n",
    "\n",
    "X.head()\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.machine_learning.ex4 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Split Your Data\n",
    "Use the train_test_split function to split up your data.\n",
    "\n",
    "Though you could use any number for the random_state, use `random_state=1` so the `check` functions know what to expect when they verify your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> The training data had different rows than expected"
      ],
      "text/plain": [
       "Incorrect: The training data had different rows than expected"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y)\n",
    "print(\"Incorrect\")\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "print(\"Correct\")\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> The function you need to import is part of sklearn. When calling the function, the arguments are X and y"
      ],
      "text/plain": [
       "Hint: The function you need to import is part of sklearn. When calling the function, the arguments are X and y"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The lines below will show you a hint or the solution.\n",
    "step_1.hint() \n",
    "# step_1.solution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Specify and Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model with the training data.\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "step_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "iowa_model = DecisionTreeRegressor(random_state=1)\n",
       "iowa_model.fit(train_X, train_y)\n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "iowa_model = DecisionTreeRegressor(random_state=1)\n",
       "iowa_model.fit(train_X, train_y)\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step_2.hint()\n",
    "step_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions with Validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> val_predictions is wrong size. Did predict with wrong data?"
      ],
      "text/plain": [
       "Incorrect: val_predictions is wrong size. Did predict with wrong data?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict with all validation observations\n",
    "val_predictions = iowa_model.predict(train_X)\n",
    "print(\"Incorrect\")\n",
    "step_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict with all validation observations\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "print(\"Correct\")\n",
    "step_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> Run predict on the right validation data object."
      ],
      "text/plain": [
       "Hint: Run predict on the right validation data object."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step_3.hint()\n",
    "# step_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect your predictions and actual values from validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top few validation predictions\n",
    "#print(_)\n",
    "# print the top few actual prices from validation data\n",
    "#print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice that is different from what you saw with in-sample predictions (which are printed after the top code cell in this page).\n",
    "\n",
    "Do you remember why validation predictions differ from in-sample (or training) predictions? This is an important idea from the last lesson.\n",
    "\n",
    "## Step 4: Calculate the Mean Absolute Error in Validation Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "\n",
    "step_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that MAE good?  There isn't a general rule for what values are good that applies across applications. But you'll see how to use this number in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Going\n",
    "\n",
    "Now that you can measure model performance, you are ready to run some experiments comparing different models. The key is to understand **[Underfitting and Overfitting](https://www.kaggle.com/dansbecker/underfitting-overfitting-and-model-optimization)**. It's an especially fun part of machine learning. \n",
    "\n",
    "---\n",
    "**[Course Home Page](https://www.kaggle.com/learn/machine-learning)**\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
